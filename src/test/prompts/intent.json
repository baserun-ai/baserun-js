{
  "model": "gpt-3.5-turbo",
  "messages": [],
  "max_tokens": 500,
  "temperature": 0.3
}